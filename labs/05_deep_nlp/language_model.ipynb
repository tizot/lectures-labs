{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character-level Language Modeling with LSTMs\n",
    "\n",
    "This notebook is adapted from [Keras' lstm_text_generation.py](https://github.com/fchollet/keras/blob/master/examples/lstm_text_generation.py).\n",
    "\n",
    "Steps:\n",
    "\n",
    "- Download a small text corpus and preprocess it.\n",
    "- Extract a character vocabulary and use it to vectorize the text.\n",
    "- Train an LSTM-based character level langague model.\n",
    "- Use the trained model to sample random text with varying entropy levels.\n",
    "- Implement greedy and beam-search deterministic decoders.\n",
    "\n",
    "\n",
    "**Note**: fitting language models is compute intensive. It is recommended to do this notebook on a server with a GPU or powerful CPUs that you can leave running for several hours at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading some text data\n",
    "\n",
    "Let's use some publicly available philosopy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.utils.data_utils import get_file\n",
    "\n",
    "URL = \"https://s3.amazonaws.com/text-datasets/nietzsche.txt\"\n",
    "\n",
    "corpus_path = get_file('nietzsche.txt', origin=URL)\n",
    "text = open(corpus_path).read().lower()\n",
    "print('Corpus length: %d characters' % len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(text[:600], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = text.replace(\"\\n\", \" \")\n",
    "split = int(0.9 * len(text))\n",
    "train_text = text[:split]\n",
    "test_text = text[split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a vocabulary of all possible symbols \n",
    "\n",
    "To simplifly things, we build a vocabulary by extracting the list all possible characters from the full datasets (train and validation).\n",
    "\n",
    "In a more realistic setting we would need to take into account that the test data can hold symbols never seen in the training set. This issue is limited when we work at the character level though.\n",
    "\n",
    "Let's build the list of all possible characters and sort it to assign a unique integer to each possible symbol in the corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "`char_indices` is a mapping to from characters to integer identifiers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(char_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted(char_indices.items())[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`indices_char` holds the reverse mapping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(indices_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indices_char[52]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While not strictly required to build a language model, it's a good idea to have a look a the distribution of relative frequencies of each symbol in the corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counter = Counter(text)\n",
    "chars, counts = zip(*counter.most_common())\n",
    "indices = np.arange(len(counts))\n",
    "\n",
    "plt.figure(figsize=(14, 3))\n",
    "plt.bar(indices, counts, 0.8)\n",
    "plt.xticks(indices, chars);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's cut the dataset into fake sentences at random with some overlap. Instead of cutting at random we could use a English specific sentence tokenizer. This is explained at the end of this notebook. In the mean time random substring will be good enough to train a first language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_length = 40\n",
    "step = 3\n",
    "\n",
    "\n",
    "def make_sequences(text, max_length=max_length, step=step):\n",
    "    sequences = []\n",
    "    next_chars = []\n",
    "    for i in range(0, len(text) - max_length, step):\n",
    "        sequences.append(text[i: i + max_length])\n",
    "        next_chars.append(text[i + max_length])\n",
    "    return sequences, next_chars    \n",
    "\n",
    "\n",
    "sequences, next_chars = make_sequences(train_text)\n",
    "sequences_test, next_chars_test = make_sequences(test_text, step=10)\n",
    "\n",
    "print('nb train sequences:', len(sequences))\n",
    "print('nb test sequences:', len(sequences_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's shuffle the sequences to break some of the dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "sequences, next_chars = shuffle(sequences, next_chars,\n",
    "                                random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "next_chars[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting the training data to one-hot vectors\n",
    "\n",
    "Unfortunately the LSTM implementation in Keras does not (yet?) accept integer indices to slice columns from an input embedding by it-self. Let's use one-hot encoding. This is slightly less space and time efficient than integer coding but should be good enough when using a small character level vocabulary.\n",
    "\n",
    "**Exercise:** \n",
    "\n",
    "One hot encoded the training `data sequences` as `X` and `next_chars` as `y`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_sequences = len(sequences)\n",
    "n_sequences_test = len(sequences_test)\n",
    "voc_size = len(chars)\n",
    "\n",
    "X = np.zeros((n_sequences, max_length, voc_size),\n",
    "             dtype=np.float32)\n",
    "y = np.zeros((n_sequences, voc_size), dtype=np.float32)\n",
    "\n",
    "X_test = np.zeros((n_sequences_test, max_length, voc_size),\n",
    "                  dtype=np.float32)\n",
    "y_test = np.zeros((n_sequences_test, voc_size), dtype=np.float32)\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load solutions/language_model_one_hot_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring perplexity\n",
    "\n",
    "The NLP community measures the quality of probabilistic model using [perplexity](https://en.wikipedia.org/wiki/Perplexity).\n",
    "\n",
    "In practice perplexity is just a base 2 exponentiation of nll:\n",
    "\n",
    "$$perplexity_\\theta = 2^{-\\frac{1}{n} \\sum_{i=1}^{n} log_2 (p_\\theta(x_i))}$$\n",
    "\n",
    "**Exercise**: implement a perplexity function with model predicted probabilities `y_pred` and `y_true` for the encoded ground truth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perplexity(y_true, y_pred):\n",
    "    \"\"\"Compute the perplexity of model predictions.\n",
    "    \n",
    "    y_true is one-hot encoded ground truth.\n",
    "    y_pred is predicted likelihoods for each class.\n",
    "    \n",
    "    2 ** -mean(log2(p))\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    return 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load solutions/language_model_perplexity.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_true = np.array([\n",
    "    [0, 1, 0],\n",
    "    [0, 0, 1],\n",
    "    [0, 0, 1],\n",
    "])\n",
    "\n",
    "y_pred = np.array([\n",
    "    [0.1, 0.9, 0.0],\n",
    "    [0.1, 0.1, 0.8],\n",
    "    [0.1, 0.2, 0.7],\n",
    "])\n",
    "\n",
    "perplexity(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A perfect model has a minimal perplixity of 1.0 (negative log likelihood of 0.0):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "perplexity(y_true, y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building recurrent model\n",
    "\n",
    "Let's build a first model and train it on a very small subset of the data to check that it works as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(max_length, voc_size)))\n",
    "model.add(Dense(voc_size, activation='softmax'))\n",
    "\n",
    "optimizer = Adam(lr=0.001, clipnorm=10)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's measure the perplexity of the randomly initialized model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def model_perplexity(model, X, y):\n",
    "    predictions = model.predict(X, verbose=1)\n",
    "    return perplexity(y, predictions)\n",
    "\n",
    "\n",
    "model_perplexity(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train the model for one epoch on a very small subset of the training set to check that it's well defined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "small_train = slice(0, 100000, 40)\n",
    "\n",
    "model.fit(X[small_train], y[small_train], validation_split=0.1,\n",
    "          batch_size=128, nb_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_perplexity(model, X[small_train], y[small_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_perplexity(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling random text from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Greedy deterministic decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beam search for deterministic decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Better handling of sentence boundaries\n",
    "\n",
    "To simplify things we used the lower case version of the text and we ignored any sentence boundaries. This prevents our model to learn when to stop generating characters. If we want to train a model that can start generating text at the beginning of a sentence and stop at the end of a sentence, we need to provide it with sentency boundary markers in the training set and use those special markers when sampling.\n",
    "\n",
    "The following give an example of how to use NLTK to detect sentence boundaries in English text.\n",
    "\n",
    "This could be used to insert an explicit \"end_of_sentence\" (EOS) symbol to mark separation between two consecutive sentences. This should make it possible to train a language model that explicitly generates complete sentences from start to end.\n",
    "\n",
    "Use the following command (in a terminal) to install nltk before importing it in the notebook:\n",
    "\n",
    "```\n",
    "$ pip install nltk\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_with_case = open(corpus_path).read().replace(\"\\n\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "sentences = sent_tokenize(text_with_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist([len(s.split()) for s in sentences], bins=30);\n",
    "plt.title('Distribution of sentence lengths')\n",
    "plt.xlabel('Approximate number of words');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first few sentences detected by NLTK are too short to be considered real sentences. Let's have a look at short sentences with at least 20 characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted_sentences = sorted([s for s in sentences if len(s) > 20], key=len)\n",
    "for s in sorted_sentences[:5]:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some long sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for s in sorted_sentences[-3:]:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NLTK sentence tokenizer seems to do a reasonable job despite the weird casing and '--' signs scattered around the text.\n",
    "\n",
    "Note that here we use the original case information because it can help the NLTK sentence boundary detection model make better split decisions. Our text corpus is probably too small to train a good sentence aware language model though, especially with full case information. Using larger corpora such as a large collection of [public domain books](http://www.gutenberg.org/) or Wikipedia dumps. The NLTK toolkit also comes from [corpus loading utilities](http://www.nltk.org/book/ch02.html).\n",
    "\n",
    "The following loads a selection of famous books from the Gutenberg project archive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('gutenberg')\n",
    "book_selection_text = nltk.corpus.gutenberg.raw().replace(\"\\n\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(book_selection_text[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Book corpus length: %d characters\" % len(book_selection_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do an arbitrary split. Note the training set will have a majority of text that is not authored by the author(s) of the validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "split = int(0.9 * len(book_selection_text))\n",
    "book_selection_train = book_selection_text[:split]\n",
    "book_selection_validation = book_selection_text[split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus exercises\n",
    "\n",
    "- Adapt the previous language model to handle explicitly sentence boundaries with a special EOS character.\n",
    "- Train a new model on the random sentences sampled from the the book selection corpus with full case information.\n",
    "- Adapt the random sampling code to start sampling at the beginning of sentence and stop when the sentence ends.\n",
    "- Train a deep GRU (e.g. two GRU layers instead of one LSTM) to see if you can improve the validation perplexity.\n",
    "- Git clone the source code of the [Linux kernel](https://github.com/torvalds/linux) and train a C programming language model on it. Instead of sentence boundary markers, we could use source file boundary markers for this exercise.\n",
    "- Try to increase the vocabulary size to 256 using a [Byte Pair Encoding](https://arxiv.org/abs/1508.07909) strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
